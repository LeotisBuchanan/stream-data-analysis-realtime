<!DOCTYPE html>
<html>
  <head>
    <title>Introduction to Regular Expression</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: bold;
      }

     .list{
         font-weight: bold;
     }

     .tweet{
         background: none repeat scroll 0 0 rgba(231, 228, 157, 0.25);
         border-color: rgba(231, 228, 157, 0.15);
         border-style: solid;
         border-width: 5px;
         color: rgba(0, 0, 0, 0.65);
         font-style: italic;
         margin-bottom: 20px;
         padding: 10px 15px;

     }
     .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono';
         font-weight:normal;
         color:#E82C0C; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle
## CKME136 Capstone Project
# A big Data application for Real Time classification of Symptoms of illness in Toronto, using twitter data
 by Leotis Buchanan(LeotisBuchanan@gmail.com)

June 17, 2015
---

# Problem

1. Quickly Detecting disease outbreaks using user social media posts.
2. Handling and processing large quantity of data in real time(volume, velocity).
3. Using the data to predict future illness outbreak.

---

# Dataset and datasource

1. Twitter via their data stream api.


## The schema for a tweet

The schema/structure of the tweet data collected was generated and printed using the following snippet of code:

```python
from pyspark.sql import SQLContext
sqlContext = SQLContext(sc)
# Create the DataFrame
df = sqlContext.jsonFile("twitter_stream.20150519-084907.json")
# Show the content of the DataFrame
df.show()
# Print the schema in a tree format
df.printSchema()


```
---
# The data format of a single tweet.


```
root
 |-- _corrupt_record: string (nullable = true)
 |-- contributors: string (nullable = true)
 |-- coordinates: struct (nullable = true)
 |    |-- coordinates: array (nullable = true)
 |    |    |-- element: double (containsNull = true)
 |    |-- type: string (nullable = true)
 |-- created_at: string (nullable = true)
 |-- entities: struct (nullable = true)
 |    |-- hashtags: array (nullable = true)
 |    |    |-- element: struct (containsNull = true)
 |    |    |    |-- indices: array (nullable = true)
 |    |    |    |    |-- element: long (containsNull = true)
```



---
# Approach

![Approach](https://raw.githubusercontent.com/LeotisBuchanan/stream-data-analysis-realtime/master/final-report/process.png)
1. Tweet collection
2. Tweet Cleaning and transformation
3. Filtering
4. Data transformation
5. Text Preprocessing and feature generation

---
# Training the Classifier
1. Generate feature vectors each tweet text.
   ```python
    def generatedHashedFeatures(tweet):
       htf = HashingTF()
       lp = LabeledPoint(tweet.label, htf.transform(tweet.text))
       return lp
   ```
2. Manually labelled about 1000 tweets.

.tweet[
user_id_100,,,en,Tue May 26 00:58:25 +0000 2015, MamaJaws not everyone I m
itching to formulate an opinion but cannot because there isn t enough data ,0
]
.tweet[
user_id_01,,,en,Thu May 28 16:59:32 +0000 2015,
Another dialysis stay under my belt lots of itching and cramping Lord have mercy ,1
]

---
3. Split data in training and test data.
```
training, test = data.randomSplit([0.6, 0.4], seed = 0)
```

4. Train and persist a naive bayes model.
```
model = NaiveBayes.train(training, 1.0)
```
---

# Classifying tweets in Real Time

1. .list[Apache Spark] - Apache Spark is a fast and general-purpose cluster computing system
2. .list[mlib] -  Machine Learning Library
3. .list[kafka]- A high-throughput distributed messaging system.
4. .list[twitter]- streaming api.
5. .list[deployed to AWS]

---

# Application Architecture

![Architecture](https://raw.githubusercontent.com/LeotisBuchanan/stream-data-analysis-realtime/master/final-report/realtimetweetsystem_arch.png)


---
# Conclusion and results

1. Created a spark application that streams and classify tweets in real time.
2. Trained naive bayes classifier model.
3. I have made the source code for the project available on my github repo.


---
# Future work

1. Create android app to visualize the output of the application.
2. Deploy the application to databricks cloud.
3. Incooperate other datasources.
3. Fix bugs etc.


---
class: center, middle
#Questions ?

    </textarea>
    <!--<script src="http://gnab.github.io/remark/downloads/remark-0.5.9.min.js" type="text/javascript">
    </script> -->
    <script src="out/remark.js" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create();
    </script>
  </body>
</html>
